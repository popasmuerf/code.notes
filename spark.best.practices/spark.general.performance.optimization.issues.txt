https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/performance_optimization/how_many_partitions_does_an_rdd_have.html

How we can check jobs(at least locally)
=============================================
*	http://localhost:4040/jobs/
*	http://localhost:4040/stages/
*	http://localhost:4040/storage/
*	http://localhost:4040/environment/
*	http://localhost:4040/executors/

How Many Partitions does an RDD Have ?
==========================================================================
For tuning and troubleshooting, it's often necessary to know how many partitions
an RDD represents.  There are a few ways to find this information:



View Task Execution Against Partitions Using the UI
---------------------------------------------------------------------
When a stage executes, you can see the number of partitions for a given
stage  in the Spark UI.  For example, the following simple job creates
an RDD of 100 elements across 4 partitions, then distributes a dummy
map task before collecting the elements back to the driver program

val someRDD = sc.parallelize(1 to 100 , 4) // specfied 4 partitions(across 4 nodes)
someRDD.map(x => x).collect() 


^^^^We can check the status of our jobs via the URL:  http://localhost:4040/stages/




View Partition Caching Using the UI
================================================================================
When persisting (also known as caching) RDDs, it's useful to understand how many partitions have been stored.
The example below is identical to the one prior, except that we'll now cache the RDD prior to processing
it.  After this completes, we can use the UI to understand what has been stored form this operation

UI context :  URL localhost:4040/storage/



Inspect RDD Partitions Programatically
=================================================================================
In the scala API, an RDD holds a reference to it's Array of partitions, which yu can use to find out
how many partitions there are:

val someRDD2 = sc.parallelize(1 to 100 , 30) // specfied 4 partitions(across 4 nodes)
someRDD2.getNumPartitions  //tell me programatically how many partions/nodes are involved in this...is should == 30 , cause I set it that way






