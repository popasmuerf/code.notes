https://meinit.nl/enable-an-apple-mac-os-x-machine-as-a-syslog-server


Spark Streaming + Kafka Integeration Guide --> Approach #!
==================================================
This approach uses a Reciever to recieve the data.
The Recieved is implemented using the Kafka high-level 
consumer API.  As with all recievers, the data 
recieved from Kafka through a Reciever is stored in Spark
executors, and then jobs luanched by Spark Steaming 
processes the data.

Drawbacks:
===================================================
However, under default configuration, this approach can
lose data under failures (see reciever reliability).
To ensure zero-data loss, you have to additioanlly enable Write
ahead Logs in Spark Streaming.


Direct Approach....No Recievers
==================================================
introduced in Spark 1.3.  to ensure stronger end to end guarantees.
Instead of using recievers to reciver data, this apprach periodically queries Kafka for the latest offsets in each  topic + partition, and accordingly defines
the offset ranges to process in each batch.  When the jobs to process the data are luanched, Kafka's 
simple consumer API isused to read the defined ranges of
offsets from Kafka.

Drawbacks:
===================================================
Note that one disadvantage of this approach is that it does not update offsets in Zookeeper, hence Zookeeper-based Kafka monitoring tools will not show progress. However, you can access the offsets processed by this approach in each batch and update Zookeeper yourself (see below).





