spark.jobserver.SparkJob

Nan
John Uchiama

https://github.com/spark-jobserver/spark-jobserver/blob/master/README.md#getting-started-with-spark-job-server

WordCountExample walk-thru
==============================
*package your jar
*send to server
-------------------------------
Let's assume we have a simple
spark job named:

	WordCountExample

Steps:
1. package your code into a runnable
jar using your build tools(sbt,ivy,gradle,whatevs)

2. upload you new jar to the cluster(?):

	curl --data-binary @job-server-tests/target/scala-2.11/ \
	job-server-tests-$VER.jar \
	localhost:8090/jars/test

	OK


Modes ad-hoc : Single, Unrelated Jobs(Transient Context)
=====================================
Ok...so we packaged our test app in a 
jar and loaded it up to the location
of our jobserver....

Starting an ad-hoc word count job,
meaning that the job server will create
it's own SparkContext, and then return
a job ID for subsequent querying....

Starting an ad-hoc word count
--------------------------------------
> curl -d "input.string = a b c a b see" \
  localhost:8090/jobs?appName=test&classPath=spark.jobserver.WordCountExample"
  
200 OK
  {
  	"duration":"Job not done yet",
  	"classPath": "spark.jobserver.WordCountExmaple",
  	"startTime":"2016-06-19T16:27:12.196+05:30",
  	"context":"b7ea0eb5-spark.jobserver.WordCountExample",
  	"status": "STARTED"
  	"jobId": "5453779a-f004-45fc-a11d-a39dae0f9bf4"
  }


What if we want to feed in a text file config
and POST using curl, we want to use the
option parameter :

	"--data-binary"

otherwise curl will munge your line
separator chars:

# Feeding text file config via POST
> curl --data-binary @my-job-config.json \
  jobs?appName=test&classPath=spark.jobserver.WordCountExample"

Note: If you want to use UTF-8 encoding...pass the correct meta data to CURL...or you my get
an encoding you did not expect....



Querying submited jobs
===========================================
#Querying the job.server about
#our job we just submitted

>curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4

200 OK
{
  "duration": "6.341 secs",
  "classPath": "spark.jobserver.WordCountExample",
  "startTime": "2015-10-16T03:17:03.127Z",
  "context": "b7ea0eb5-spark.jobserver.WordCountExample",
  "result": {
    "a": 2,
    "b": 2,
    "c": 1,
    "see": 1
  },
  "status": "FINISHED",
  "jobId": "5453779a-f004-45fc-a11d-a39dae0f9bf4"



Creating a Job Server Project
======================================
https://github.com/spark-jobserver/spark-jobserver/blob/master/README.md#getting-started-with-spark-job-server

https://github.com/spark-jobserver/spark-jobserver.g8/blob/master/src/main/g8/src/main/scala/%24package%24/WordCountExample.scala

Creating a project from scratch using
"giter8 template"
--------------------------------------
There is a a giter8 template available at:

	https://github.com/spark-jobserver/spark-jobserver.g8

Building shit:
--------------------------------------
> sbt new spark-jobserver/spark-jobserver.g8







