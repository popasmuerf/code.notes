http://phantomjs.org/

PhantomJS -- Scriptable Headless Browser



Important: PhantomJS development is suspended until 
further notice.




What is PhantomJS ?
==========================================
PhantomJs is a headless web browser scriptable
with JavaScript.


Usig QtWebKit as the back-end, it offers fast and
native suport for various web standards:

	1.	DOM handling
	2.	CSS selector
	3.	JSON 
	4. 	Canvas
	5. 	SVG



The following simple scripts for PhantomJS loads
Google homepage, waits a bit, and then captures
it to an image.


//code

	var page = require('webpage').create();
	function fn = {
		setTimeout(function(){
			page.render('google.png');
			phantom.exit() ;
		},200);
	}
	page.open('http://www.google.com', fn);




PhantomJs is an optimal solution for :
==========================================

*	Page automation:
	-	Acess webpages and extract information using the
		standard DOM API, or with usual libraries like
		JQuery


*	Screen capture
	-	Programattically caputure web contents, including
		SVG and Canvas

	-	Create web site screen shots with thumbnail 
		preview

*	Headless website testing
	-	Run functional tests with frameworks such as 
			*	Jamine, QUnit, Mocha, WebDriver,etc

*	Network monitoring
	-	Monitor page loading and export as standard
		HaR files.  auomate performance annalysis using
		YSlow and Jenkins.




Page Automationwith PhantomJS
=============================================
Because PhaontomJS can load and manipuluate a web page, it is perfect
to carry out various page automation tasks.


DOM manipulation
---------------------------------------------
Sinc ethe script is executed as if it is running
on a web browser, standard DOM scripting and CSS selectors
work just fine.


The following useragent.js  example demonstrates reading the
property:

	textContent property of the element whose id is :

		qua


// code

var page = require('webpage').create();
console.log('The default user agent is ' + page.settings.userAgent);
page.settings.userAgent = 'SpecialAgent';
page.open('http://www.httpuseragent.org', function(status) {
  if (status !== 'success') {
    console.log('Unable to access network');
  } else {
    var ua = page.evaluate(function() {
      return document.getElementById('qua').textContent;
    });
    console.log(ua);
  }
  phantom.exit();
});




The above example also shows the approach to customize the User-Agent 
string seen by teh remote web sever

side note...what is the User-Agent String ?
-------------------------------------------------
The User-Agent request-header field contains information
about he user agent originating the request.  This is
for statistical purposes, the tracing of protocol violations,
and automated recognition of user agents for the 
sake of tailoring responses.t avoid particular user agent
limitations.  

//example

User-Agent ="User-Agent" ":" 1*( product | comment )






Ue jQuery and Otehr Libraries
------------------------------------------------

As of version 1.6, you area lso able to include jQuery into your page using

	page.includeJs as follows:


	//code

var page = require('webpage').create();
page.open('http://www.sample.com', function() {
  page.includeJs("http://ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.min.js", function() {
    page.evaluate(function() {
      $("button").click();
    });
    phantom.exit()
  });
});




The Webpage instance
====================================================
Suppose you have an instance of the webpage:
	// code 
	var page = require('webpage').create() ;

what can be etracted and executed on it ?


Attributes
--------------------------------------------------------
	
	*	page.conGoForward -> boolean
		-	If window.history.forawrd coulw be a valid action

	*	page.canGoBack -> boolean
		-	If window.history.ack would be a valid action

	*	page.clipRect -> object
		-	


added : BadIps.py
        version: initial version
        date : 2018.09.07
        author : mdb172
        modified by: mdb172
        modifications: Added code for despositing body of  data retrieved 
        from site crawling into data object store(minio/s3)





@Pavel just to be clear.....
1. OxPath uses MongoDB for both(?):
	1.1 picking up jobs to run
	1.2 Storing data retrieved from websites

2. PhantomJs for rendering target data that can only be
   achieved via scripting and then using the OxPath
   query language to actually retrieve the data from the rendered
   page(?)

3. We really don't have to worry about the mechanics of #1
   as Crawlee should be able to use the OxPath api to run jobs
   and recieve back site date OxPath has retrieved(?)



 def parse_ip_info(self,response):
        fdir = ''
        body = response.body
        if body:
            iplist = re.findall(self.pttr_ip,body)
            if (len(iplist) > 1):
                fname = 'badip-' + iplist[1] + "-" + strftime("%Y-%m-%d %H:%M:%S", gmtime() ).replace(" ","-")
                yield swob.FileStoreItem(data=body,filename=fname,filedir=fdir)
            else:
                fname = 'badip-EMPTY_RESP' + "-" + strftime("%Y-%m-%d %H:%M:%S", gmtime() )
                yield swob.FileStoreItem(data=body,filename=fname,filedir=fdir)