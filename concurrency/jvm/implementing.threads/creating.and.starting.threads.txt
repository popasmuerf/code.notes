http://tutorials.jenkov.com/java-concurrency/creating-and-starting-threads.html


Creating a thread in Java like this.
======================================
Thread thread = new Thread() ;
thread.start() ;



Thread Subclass
====================================
public class ThisThread extends Thread{
        public void run(){
                System.out.println("ThisThread running") ;
        }
}



Thread thisThread = new ThisThread() ;
thisThread.start() ;



                -or-


Thread thisThread = new Thread(){
        public void run(){
                System.out.println("Thread is running") ;
        }
}
thread.start() ;


Runnable Interface implementation
======================================
public class ThisThread extends Runnable{
        public void run(){
                System.out.println("ThisThread running") ;
        }
}


                -or-


Thread thread = new Thread( new Runnable(){
        public void run(){
                System.out.println("ThisThread running") ;
        }
}) ;


thread.start() ;
        -or-
thread.run() ;


Difference between Thread.start() and Thread.run() 
=======================================================
run()
---------------------------------------------------------
If this thread was constructed using a separate Runnable run object, then that Runnable object's run method is called; otherwise, this method does nothing and returns.

start()
--------------------------------------------------------
Causes this thread to begin execution; the Java Virtual Machine calls the run method of this thread.




Concurrency Models and Distributed System
Similarities
=====================================
Application concurrency model share the following
similarities:

Concurrent applications:
        * Threads communicate with one another
        * worker threads(analougus to load balancing nodes)

Distributed Systems     
        * Different processes communicate with one another
        * load balancing nodes(analogus worker threads)


Parallel Workers Model
==========================================
Incoming jobs are assigned to different workers.

Delegator ------> Worker
        |
        |-------> Worker
        |
        |-------> Worker

Attributes of Parallel Workers Model
-----------------------------------------
        * Most commonly used model
        * Utilities in java.util.concurrent uses this model
        * Delegator distributes work to worker threads
        * Worker threads complete jobs in full
        * Worker threads may work concurrently or parrallel
          on seperate CPUs
        * Most Java enterprise application servers use this
          model
        
Advantages of Parrallel Workers
-----------------------------------------
        * Easy to comprehend
        * Easy to scale out application via adding more
          workers
        * More workers reduce CPU idleness and increases
          time to finish I/O processing

Disadvantages of Parrallel Workers
------------------------------------------
        * Access to shared data can become complicated
        * Access to shared memory can become complicated
        * Any change to presistence in memory or some other
          model must be visible to all threads
        * Race conditions have to be accounted for
        * Deadlock conditions have to be accounted for
        * A degree of parralization/concurrency is lost
          (lose of autonomy) as they all must wait for each
          other to fully release resources
        * Resources are often blocking..which can lead
          to high contention rates..which in turn can
          reduce your concurrent algorithm to a serial
          queue
        * Modern non-blocking algorithms may decrease
          contention but they are difficult to implement
        * Persistent data structures are a possible solution
          but they tend to have poor performance

Stateless Workers
--------------------------------------------------
Shared state can be modified by other threads
in the system.  Therefore workers must re-read
the state every time it needs it, to ensure that
it is working on the most recent copy...this is
true whether the shared state is kept in memory
or in an external database.  A woker that does not
keep state internally (but re-reads it every time it 
is needed) is called stateless.  Stateless strategies
can be slow....for obvious reasons.


Job ordering is Nonderterministic
---------------------------------------------
There is no way to guarantee which jobs are
exeicuted first or last.



Assembly Line
====================================================
Who uses it ?:
        * reactive systems (just another name for event)
        * event driven systems(just another name for reactive)


Delegator ---------->Worker------->Worker----->Worker

How does Assembly Line work ?
------------------------------------------------------
        * Workers are organized like workers at 
          an assembly line in a factory
        * Each worker only performs a part of the full job
        * When that part is finished the worker forwards
          the job to the next worker
        * Each worker is running its own thread, and shares
          no state with other workers(shared nothing concurrency model)
        

Systems that use assembly/reactive/event driven concurrency
mdodels are usually designed to use non-blocking I/O.  Non-blocking I/O  means that when a worker starts an I/O operation(reading files or data from a network stream) the worker does not wait for the I/O call to finish.  I/O is 
slow...so waiting for the I/O operation to finish is a waste
of CPU time.  The CPU should be doing something esle in
the meanwhile.   When the I/O operations finishes, the next
worker in the assembly line continues working on the job, until that has to start an I/O operation

In reality this is what a non-blocking I/O reactive/event
driven systems looks like....


Delegator------>Worker------->Worker----->Worker
        |
        |------->Worker------->Worker----->Worker
        |
        |------->Worker------->Worker----->Worker

^^^^For instance...jobs may  even be forwarded to more than
one worker for concurrent processing.  For instance, a job may be forwared to both a job executor and a job logger.
This improved diagram illustrates how all three assembly
lines finish off by forwarding their jobs to the same worker
(the last woerker in the middle assembly line):


The diagram below illustrates how reactive/event driven
systems may get even more complicated....


Delegator-->Worker-->Worker-->Worker--
        |                             |
        |-->Worker-->Worker-->Worker----> Worker
        |                             |
        |-->Worker- >Worker-->Worker--



Reactive, Event Driven Systems
===============================================
Systems using an assembly line concurrency model are also
sometimes called reactive systems, or event driven systems.
The system's workers react to events occuring in the system,
either recieved from the outside world or emitted by other 
workers.  Examples of events could be an incomming
HTTP request, or that a ceertain file finished loading
into memory etc...

Examples of some of the more popular reactive/event
driven systems
==================================================
        * Vert.x(jvm)
        * Akka (scala/jvm)
        * Node.JS (jscript)



Actors vs. Channels
===================================================
Actors and channels are two similar examples of 
assembly line(or reactive/event driven) models.

In the actor model..each worker is called an "actor".
Actors can send messages directly to each other.
Messages are sent and processed
asynchronously.  Actors can be used to
implement one or more job processing
assembly lines, as descrbied earlier.  Here is
a diagram illustrating the actor model:


Actor------>Actor-->Actor-->Actor---
        |                          |
        |-->Actor-->Actor-->Actor--> Actor
        |                          |
        |-->Actor-->Actor-->Actor---  
     

    


Channel Model
==================================================
In the channel model, workers do not communicat directly
with each other.  Instead they publish their messages(events) on diffrent channels.  Other workers can then listen for messages on these channels without the 
the sender knowning who is listening(why would they need to know ?).  Here is a diagram illustrating the channel
model:

Delegator-->Worker-->Channel1-->Worker---->Channel5
                        |                        |
        |               |---------|              |
        |-->Worker-->Channel2-->Worker---Channel6----> Worker


Assembly Line Advantages
====================================================
        * No shared state
        * Workers/Actors are easir to implement
        * Race conditions are not a problem(mostly)
        * Workers/Actors may be stateful
        * Job ordering may be deterministic

Assembly Line disadvantages
====================================================
        * Job spread out over multiple workers
          makes pinpointing what is going on and 
          when difficult
        * Design and implimentation may be a bit more
          difficult given some systems make heavy
          use of callbacks("callback hell")
        * Race conditions are not a problem(mostly)
        * Workers/Actors may be stateful
        * Job ordering may be deterministic



Functional Parallelism
=======================================================
Functional parallelism is a third concurrency model
which is being talked about a
lot these days 

The basic idea here is that you implement your program
using function calls.  Functions can be seen as "agents"
or "actors" that send messages to each other, just like
assembly/event/reactive  that send messages to each other.
One  function calls another, that is similar to sending a 
message.

All parameters are passed to the function are copied, so 
no entity outside the recieveing function
can manipulate the data.  This copying is essential
to avoiding race conditions on the shared data.  This makes
the function exectuion similar to an atomic operation;.

Each function can be executed independently, each function
call can be eecuted on sperate CPUs.  This i means that an algorithm implemented functionaly can be executed in parallel, on multple CPUs.


With Java 7 we got the java.util.concurrent package contains
the operation:

        ForkAndJoinPool

which can help us implement something similar to
functional parallelism.  With Java 8 we got parallel streams
which can help you parallelize the iteration of large
collections.  Keep in mind that htere are developers who 
are critical of the ForkAndJoinPool


Why




